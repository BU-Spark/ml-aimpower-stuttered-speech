{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5c67f2f-ea8f-4f11-abce-d1d3128e96fa",
   "metadata": {},
   "source": [
    "# Azure Evaluation On Audio Length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbdd4e2-8579-49e0-a711-d24ffc3c74a0",
   "metadata": {},
   "source": [
    "1. Compute Audio Length for Each Transcription\n",
    "2. Compute Error\n",
    "3. Generate Plots\n",
    "***\n",
    "### Error Metrics\n",
    "1. WER\n",
    "2. ROUGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69592710-05c0-49db-969a-2ab2907b86e9",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da19702-894b-4369-b35f-9d655a21e09c",
   "metadata": {},
   "source": [
    "## Using Custom Kernel on SCC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04ec647-3a37-482b-9e1a-66e0bdde5241",
   "metadata": {},
   "source": [
    "SCC sometimes has the problem with installed library not importable [`module not found` error], this is an alternative.\n",
    "\n",
    "Assuming you have a conda environment created, you would do the following:\n",
    "1. `conda install -c anaconda ipykernel` \n",
    "2. `python -m ipykernel install --user --name=<env name>`\n",
    "3. If the new kernel cannot be found, relaunch a new SCC instance\n",
    "\n",
    "**Remember to switch to the conda env kernel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fe928a-ca35-4cd4-8471-248b5f5f71e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_transcript_path = \"/projectnb/ds549/projects/AImpower/datasets/updated_annotation_deid_full\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b325a93e-56aa-418e-acaa-486fc77eade0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pandas numpy scipy tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca843f0-7694-4cf1-be73-c293515a689a",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc5f38c-5cdb-40c7-a600-b3759e18ec96",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports & Ingestion of Data\n",
    "**We will be using the data generated from `azure-stu-eval.ipynb`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4a6e2a-bc13-4ca5-b9e5-8f608aeb675f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy \n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebd1487-9f0f-41d6-8c09-e381e0731f07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net_data = pd.DataFrame(columns=[\"Filename\", \"Start_time\", \"End_time\", \"Transcript\"]) \n",
    "\n",
    "cols = list(pd.read_csv(\"net_aigenerated_data_azure_performance_stu.csv\", nrows=1))\n",
    "print(cols)\n",
    "\n",
    "net_aigenerated_data_azure = pd.read_csv('/projectnb/ds549/projects/AImpower/evaluation-azure/net_aigenerated_data_azure_performance_stu.csv', delimiter=',', usecols =[i for i in cols if \"Unnamed:\" not in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13120587-74b5-4ba6-86f8-44a9065e592f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for folder in os.listdir(ds_transcript_path):\n",
    "    if folder == \"command_stats.xlsx\" or folder == \"command_stats.csv\":\n",
    "        continue\n",
    "    for audio_sample in os.listdir(os.path.join(ds_transcript_path, f\"{folder}\")):\n",
    "        if (\"_A.txt\" in audio_sample):\n",
    "            net_data = pd.concat([net_data, pd.read_csv(os.path.join(ds_transcript_path, f\"{folder}/{audio_sample}\"), sep=\"\\t\", names=[\"Start_time\", \"End_time\", \"Transcript\"]).assign(Filename=f\"D{folder}_A\")])\n",
    "        if (\"_B.txt\" in audio_sample):\n",
    "            net_data = pd.concat([net_data, pd.read_csv(os.path.join(ds_transcript_path, f\"{folder}/{audio_sample}\"), sep=\"\\t\", names=[\"Start_time\", \"End_time\", \"Transcript\"]).assign(Filename=f\"D{folder}_B\")])\n",
    "        if (\"P\" in audio_sample):\n",
    "            net_data = pd.concat([net_data, pd.read_csv(os.path.join(ds_transcript_path, f\"{folder}/{audio_sample}\"), sep=\"\\t\", names=[\"Start_time\", \"End_time\", \"Transcript\"]).assign(Filename=f\"P{folder}\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a17e6c-21da-465c-a1ce-924032886027",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask_pattern = r\"\\<.*?\\>\"\n",
    "repetition_pattern = r\"\\[.*?\\]\"\n",
    "annotation_pattern = r\"/\\w\"\n",
    "\n",
    "\n",
    "net_data = net_data.assign(Cleaned_Transcript=net_data['Transcript'].apply(lambda x: re.sub(annotation_pattern, \"\", re.sub(repetition_pattern, \"\", re.sub(mask_pattern, \"\", x)))))\n",
    "net_data = net_data.assign(Stutterance_Count=net_data['Transcript'].apply(lambda x: len(re.findall(mask_pattern, x)) + len(re.findall(repetition_pattern, x)) + len(re.findall(annotation_pattern, x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4172489-c3b1-479c-bd49-ed4a083b37f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0653e75f-77f8-439b-8345-efbe59a4ffa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Assign back the cleaned transcript and original transcript\n",
    "merged_data = net_aigenerated_data_azure.merge(\n",
    "    net_data[['Filename', 'Start_time', 'Cleaned_Transcript', 'Transcript']],\n",
    "    on=['Filename', 'Start_time'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "net_aigenerated_data_azure['Cleaned_Transcript'] = merged_data['Cleaned_Transcript']\n",
    "net_aigenerated_data_azure['GroundTruth_Transcript'] = merged_data['Transcript']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bea712-2158-4961-b44b-c604d0b0b9bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net_aigenerated_data_azure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e148c437-4788-4c44-88b4-76835ca51623",
   "metadata": {},
   "source": [
    "**Now we have raw data of all audio transcriptions from datasets [updated_annotation_deid_full] in ```net_data``` and AI predicted transcriptions in ```net_aigenerated_data_azure```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dececa5-0211-4e85-8d8b-c52f9a33e55e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## SAVING\n",
    "\n",
    "net_aigenerated_data_azure.to_csv('net_aigenerated_data_azure_performance_stu.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3d04ee-5750-407e-9260-c9cc788add04",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd950b9-9808-4490-a80c-e6262fb46e4d",
   "metadata": {},
   "source": [
    "## Compute Audio Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3357646c-679c-4aca-a99a-4f4027083475",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net_aigenerated_data_azure = net_aigenerated_data_azure.assign(Duration=net_aigenerated_data_azure['End_time']-net_aigenerated_data_azure['Start_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244485bc-00b0-4b5a-903c-db5d87b9aaaf",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9947fbf8-daa4-4c96-8ddf-b1e5f97ec252",
   "metadata": {},
   "source": [
    "## Visualization of Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf84c62-a21a-45b9-bf65-35e57c157317",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(\n",
    "    net_aigenerated_data_azure[\"Duration\"], \n",
    "    net_aigenerated_data_azure[\"WER\"], \n",
    "    alpha=0.7  # Handle overlapping points\n",
    ")\n",
    "\n",
    "plt.title(\"WER vs Audio Duration\", fontsize=16)\n",
    "plt.xlabel(\"Audio Duration\", fontsize=14)\n",
    "plt.ylabel(\"WER\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5105e4e8-cbe1-4a1b-a789-741d40403118",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(\n",
    "    net_aigenerated_data_azure[\"Duration\"], \n",
    "    net_aigenerated_data_azure[\"rouge1-precision\"], \n",
    "    facecolors=\"none\", edgecolors='r',\n",
    "    label=\"Precision\",\n",
    "    marker=\"8\",\n",
    "    alpha=0.7  # Handle overlapping points\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    net_aigenerated_data_azure[\"Duration\"], \n",
    "    net_aigenerated_data_azure[\"rouge1-recall\"], \n",
    "    facecolors=\"none\", edgecolors='g',\n",
    "    label=\"Recall\",\n",
    "    marker=\"^\",\n",
    "    alpha=0.7  # Handle overlapping points\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    net_aigenerated_data_azure[\"Duration\"], \n",
    "    net_aigenerated_data_azure[\"rouge1-f1\"], \n",
    "    facecolors=\"none\", edgecolors='b',\n",
    "    label=\"F1\",\n",
    "    marker=\".\",\n",
    "    alpha=0.7  # Handle overlapping points\n",
    ")\n",
    "\n",
    "plt.title(\"Rouge-1 vs Audio Duration\", fontsize=16)\n",
    "plt.xlabel(\"Audio Duration\", fontsize=14)\n",
    "plt.ylabel(\"Rouge Score\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5303bb15-d387-4776-a817-7b0e3f5ca632",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(\n",
    "    net_aigenerated_data_azure[\"Duration\"], \n",
    "    net_aigenerated_data_azure[\"rouge2-precision\"], \n",
    "    facecolors=\"none\", edgecolors='r',\n",
    "    label=\"Precision\",\n",
    "    marker=\"8\",\n",
    "    alpha=0.7  # Handle overlapping points\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    net_aigenerated_data_azure[\"Duration\"], \n",
    "    net_aigenerated_data_azure[\"rouge2-recall\"], \n",
    "    facecolors=\"none\", edgecolors='g',\n",
    "    label=\"Recall\",\n",
    "    marker=\"^\",\n",
    "    alpha=0.7  # Handle overlapping points\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    net_aigenerated_data_azure[\"Duration\"], \n",
    "    net_aigenerated_data_azure[\"rouge2-f1\"], \n",
    "    facecolors=\"none\", edgecolors='b',\n",
    "    label=\"F1\",\n",
    "    marker=\".\",\n",
    "    alpha=0.7  # Handle overlapping points\n",
    ")\n",
    "\n",
    "plt.title(\"Rouge-2 vs Audio Duration\", fontsize=16)\n",
    "plt.xlabel(\"Audio Duration\", fontsize=14)\n",
    "plt.ylabel(\"Rouge Score\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcd406a-ab03-44e3-b808-34f3bfe9aa5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(\n",
    "    net_aigenerated_data_azure[\"Duration\"], \n",
    "    net_aigenerated_data_azure[\"rougel-precision\"], \n",
    "    facecolors=\"none\", edgecolors='r',\n",
    "    label=\"Precision\",\n",
    "    marker=\"8\",\n",
    "    alpha=0.7  # Handle overlapping points\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    net_aigenerated_data_azure[\"Duration\"], \n",
    "    net_aigenerated_data_azure[\"rougel-recall\"], \n",
    "    facecolors=\"none\", edgecolors='g',\n",
    "    label=\"Recall\",\n",
    "    marker=\"^\",\n",
    "    alpha=0.7  # Handle overlapping points\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    net_aigenerated_data_azure[\"Duration\"], \n",
    "    net_aigenerated_data_azure[\"rougel-f1\"], \n",
    "    facecolors=\"none\", edgecolors='b',\n",
    "    label=\"F1\",\n",
    "    marker=\".\",\n",
    "    alpha=0.7  # Handle overlapping points\n",
    ")\n",
    "\n",
    "plt.title(\"Rouge-L vs Audio Duration\", fontsize=16)\n",
    "plt.xlabel(\"Audio Duration\", fontsize=14)\n",
    "plt.ylabel(\"Rouge Score\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
